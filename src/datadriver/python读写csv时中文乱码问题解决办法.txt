1、python读写、追加csv方法：
	‘r’：只读（缺省。如果文件不存在，则抛出错误）
	‘w’：只写（如果文件不存在，则自动创建文件）
	‘a’：附加到文件末尾（如果文件不存在，则自动创建文件）
	‘r+’：读写（如果文件不存在，则抛出错误）
#例1
import csv,os
if os.path.isfile('test.csv'):
    with open("test.csv","r") as csvfile:
        reader = csv.reader(csvfile)
        #这里不需要readlines
        for line in reader:
           print line
-------------------------------------
#例2
import csv
#python2可以用file替代open
#不存在则会创建文件
with open("test.csv","w") as csvfile: 
    writer = csv.writer(csvfile)

    #先写入columns_name
    writer.writerow(["index","a_name","b_name"])
    #写入多行用writerows
    writer.writerows([[0,1,3],[1,2,3],[2,3,4]])
-------------------------------------------------
2、excel打开csv文件，可以识别编码“GB2312”，但是不能识别“utf-8”,数据库里的字符串编码是utf-8.因此：
当从csv读取数据（data）到数据库的时候，需要先把GB2312转换为unicode编码，然后再把unicode编码转换为utf-8编码：
data.decode('GB2312').encode('utf-8');当从数据库读取数据（data）存到csv文件的时候，需要先把utf-8编
码转换为unicode编码，然后再把unicode编码转换为GB2312编码：data.decode('utf-8').encode('GB2312')
3、decode('utf-8')表示把utf-8编码转换为unicode编码；encode('utf-8')表示把unicode编码转换为utf-8编码
4、Unicode只是一个符号集，它规定了符号的二进制代码，却没有规定二进制代码如何存储
5、可以使用python的编码转换模块：codecs
python unicode文件读写：
 
#coding=gbk
import codecs
  
f = codecs.open('c:/intimate.txt','a','utf-8')#这里表示把intimate.txt文件从utf-8编码转换为unicode，就可以对其进行unicode读写了
f.write(u'中文')#直接写入unicode
s = '中文'
f.write(s.decode('gbk'))#先把gbk的s解码成unicode然后写入文件
f.close()
 
f = codecs.open('c:/intimate.txt','r','utf-8')
s = f.readlines()
f.close()
for line in s:
    print line.encode('gbk')

6、python代码文件的编码

py文件默认是ASCII编码，中文在显示时会做一个ASCII到系统默认编码的转换，这时就会出错：SyntaxError: Non-ASCII character。需要在代码文件的第一行或第二行添加编码指示：

# coding=utf-8 ##以utf-8编码储存中文字符
print ‘中文’像上面那样直接输入的字符串是按照代码文件的编码来处理的，如果用unicode编码，有以下2种方式：
	s1  = u’中文’ #u表示用unicode编码方式储存信息
	s2 = unicode(‘中文’,’gbk’)
unicode是一个内置函数，第二个参数指示源字符串的编码格式。
decode是任何字符串具有的方法，将字符串转换成unicode格式，参数指示源字符串的编码格式。
encode也是任何字符串具有的方法，将字符串转换成参数指定的格式。

python字符串的编码
用 u’汉字’ 构造出来的是unicode类型，不用的话构造出来是str类型
str的编码是与系统环境相关的，一般就是sys.getfilesystemencoding()得到的值
所以从unicode转str，要用encode方法
从str转unicode，所以要用decode

例如：
# coding=utf-8   #默认编码格式为utf-8
s = u'中文' #unicode编码的文字
print s.encode('utf-8')   #转换成utf-8格式输出 
print s #效果与上面相同，似乎默认直接转换为指定编码

我的总结：
u=u'unicode编码文字'
g=u.encode('gbk') #转换为gbk格式
print g #此时为乱码，因为当前环境为utf-8,gbk编码文字为乱码
str=g.decode('gbk').encode('utf-8')   #以gbk编码格式读取g（因为他就是gbk编码的）并转换为utf-8格式输出
print str #正常显示中文
安全的方法：
s.decode('gbk','ignore').encode('utf-8′) #以gbk编码读取（当然是读取gbk编码格式的文字了）并忽略错误的编码，转换成utf-8编码输出
因为decode的函数原型是decode([encoding], [errors='strict'])，可以用第二个参数控制错误处理的策略，默认的参数就是strict，代表遇到非法字符时抛出异常；

如果设置为ignore，则会忽略非法字符；
如果设置为replace，则会用?取代非法字符；
如果设置为xmlcharrefreplace，则使用XML的字符引用。
unicode(str,‘gb2312‘)与str.decode(‘gb2312‘)是一样的，都是将gb2312编码的str转为unicode编码

7、代码文件编码：
我们在.py文件开头写的：#-*- coding:utf-8 -*- 声称了代码文件编码为utf-8，这时候，文件里面书写字符串都是utf-8编码的
8、获得系统编码：
    import sys
	print sys.getdefaultencoding()
9、sys.setdefaultencoding('utf-8')的作用是告诉系统自动解码，也就是自动完成utf-8到unicode编码的转换
	#! /usr/bin/env python 
	# -*- coding: utf-8 -*- 
	
	import sys 
	reload(sys) # Python2.5 初始化后会删除 sys.setdefaultencoding 这个方法，我们需要重新载入 
	sys.setdefaultencoding('utf-8') 
	
	str = '中文' #这是utf-8编码的字符串

	str.encode('gb18030')  #转换为gb18030编码，因为已经自动解码，所以不用写成这种样式：str.decode('utf-8').encode('gb18030')

10、字符编码判断：

	法一：
	isinstance(s, str) 用来判断是否为一般字符串
	isinstance(s, unicode) 用来判断是否为unicode
	或
	if type(str).__name__!="unicode":
	str=unicode(str,"utf-8")
	else:
	pass
	法二：
	Python chardet 字符编码判断
	使用 chardet 可以很方便的实现字符串/文件的编码检测。尤其是中文网页，有的页面使用GBK/GB2312，有的使用UTF8，如果你需要去爬一些页面，知道网页编码很重要的，虽然HTML页面有charset标签，但是有些时候是不对的。那么chardet就能帮我们大忙了。 

chardet实例
>>> import urllib
>>> rawdata = urllib.urlopen('http://www.google.cn/').read()
>>> import chardet
>>> chardet.detect(rawdata)
{'confidence': 0.98999999999999999, 'encoding': 'GB2312'}
>>>chardet可以直接用detect函数来检测所给字符的编码。函数返回值为字典，有2个元数，一个是检测的可信度，另外一个就是检测到的编码。 

chardet 安装
pip install chardet

